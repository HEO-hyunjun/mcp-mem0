# The transport for the MCP server - 'sse' / 'stdio' / streamable-http 
TRANSPORT=sse

# Port to listen on if using sse as the transport
PORT=8000

# Enable graph store (Neo4j) for advanced memory relationships
# Set to 'true' to enable graph memory features
# When enabled, run: docker-compose --profile graph up
# When disabled, run: docker-compose up (vectordb only)
# Default: false
ENABLE_GRAPH_STORE=false

# Neo4j settings (only required if ENABLE_GRAPH_STORE=true)
NEO4J_USERNAME=
NEO4J_PASSWORD=

# LLM API KEY
# For more information on environment variable settings for LLM providers, refer to the page below.
# https://docs.mem0.ai/components/llms/models

# OpenAI
# OPENAI_API_KEY=

# Anthropic
# ANTHROPIC_API_KEY=

# Azure OpenAI
# LLM_AZURE_OPENAI_API_KEY=
# LLM_AZURE_DEPLOYMENT=
# LLM_AZURE_ENDPOINT=
# LLM_AZURE_API_VERSION=

# Google AI
# GOOGLE_API_KEY=
